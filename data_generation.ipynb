{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthethic Data Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import googlemaps\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize google maps client\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "gmaps_key = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "gmaps = googlemaps.Client(key=gmaps_key)\n",
    "\n",
    "# Load in the dataset\n",
    "rides = pd.read_csv(\"Synthetic_Data/RideShares.csv\")\n",
    "\n",
    "# We want to change Airport into a new column consisting of the coordinates of said airport\n",
    "## We can use Google Map's API called Geocoding API / GeoLocation API: https://github.com/googlemaps/google-maps-services-python\n",
    "\n",
    "def get_airport_coordinates(airport_name):\n",
    "    \"\"\"\n",
    "    This function will use OpenStreetMapAPI in order to query for the coordinates of an aiport \n",
    "    \n",
    "    input: airport name we will pass into the API\n",
    "    output: a tuple that holds both (lat, long)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        geocode_result = gmaps.geocode(f'{airport_name} Airport')\n",
    "        if geocode_result: \n",
    "            location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "            return location [\"lat\"], location[\"lng\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching coordinates for {airport_name}: {e}\")\n",
    "    return None, None\n",
    "    \n",
    "# append coordinates to new columns\n",
    "rides[['latitude', 'longitude']] = rides['Airport'].apply(lambda x: pd.Series(get_airport_coordinates(x)))\n",
    "\n",
    "# drop any rows with missing coordinates (if any)\n",
    "rides.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "    \n",
    "# Make this coordinates into a normalized range (Still be able to use Euclidian Distances)\n",
    "scaler = MinMaxScaler()\n",
    "rides[[\"latitude\", \"longitude\"]] = scaler.fit_transform(rides[[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import googlemaps\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize google maps client\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "gmaps_key = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "gmaps = googlemaps.Client(key=gmaps_key)\n",
    "\n",
    "# Load in the dataset\n",
    "rides = pd.read_csv(\"Synthetic_Data/RideShares.csv\")\n",
    "\n",
    "# We want to change Airport into a new column consisting of the coordinates of said airport\n",
    "## We can use Google Map's API called Geocoding API / GeoLocation API: https://github.com/googlemaps/google-maps-services-python\n",
    "\n",
    "def get_airport_coordinates(airport_name):\n",
    "    \"\"\"\n",
    "    This function will use OpenStreetMapAPI in order to query for the coordinates of an aiport \n",
    "    \n",
    "    input: airport name we will pass into the API\n",
    "    output: a tuple that holds both (lat, long)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        geocode_result = gmaps.geocode(f'{airport_name} Airport')\n",
    "        if geocode_result: \n",
    "            location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "            return location [\"lat\"], location[\"lng\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching coordinates for {airport_name}: {e}\")\n",
    "    return None, None\n",
    "    \n",
    "# append coordinates to new columns\n",
    "rides[['latitude', 'longitude']] = rides['Airport'].apply(lambda x: pd.Series(get_airport_coordinates(x)))\n",
    "\n",
    "# drop any rows with missing coordinates (if any)\n",
    "rides.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "    \n",
    "# Make this coordinates into a normalized range (Still be able to use Euclidian Distances)\n",
    "scaler = MinMaxScaler()\n",
    "rides[[\"latitude\", \"longitude\"]] = scaler.fit_transform(rides[[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from scipy.stats import truncnorm\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Load existing data\n",
    "df = pd.read_csv('Synthetic_Data/RideShares.csv')\n",
    "df['FlightDate'] = pd.to_datetime(df['FlightDate'], errors='coerce', format='%m/%d/%Y')\n",
    "\n",
    "fake = Faker()\n",
    "random.seed(42)\n",
    "fake.seed_instance(42)\n",
    "\n",
    "def generate_data():\n",
    "    \"\"\"\n",
    "    Generate synthetic data based on real dataset's distributions\n",
    "    \"\"\"\n",
    "\n",
    "#min time for range and max time for range (these will be given in time not time intervals)\n",
    "#prices might vary for ontario vs lax\n",
    "\n",
    "    # Use real airport choices\n",
    "    airport = random.choice(['LAX', 'ONT'])\n",
    "\n",
    "    #min_wait (in .25hr increments)\n",
    "    min_wait = random.choice([x / 60 for x in range(15, 121, 15)])\n",
    "\n",
    "    #max_wait\n",
    "    max_wait = random.choice([x / 60 for x in range(120, 301, 15)])\n",
    "\n",
    "    #max spending range\n",
    "    if random.random() < 0.75:  \n",
    "        max_spending_range = random.randrange(10, 41, 5)\n",
    "    else:  \n",
    "        max_spending_range = random.randrange(40, 101, 5)\n",
    "\n",
    "    # Bags within real observed range\n",
    "    def truncated_normal(mean, std, lower=0, upper=float('inf')):\n",
    "        a, b = (lower - mean) / std, (upper - mean) / std  \n",
    "        return truncnorm.rvs(a, b, loc=mean, scale=std)\n",
    "\n",
    "    mean_bag_number = df['BagNumber'].mean()\n",
    "    std_bag_number = df['BagNumber'].std()\n",
    "    bag_no = round(truncated_normal(mean_bag_number, std_bag_number))\n",
    "    \n",
    "\n",
    "    # Dropoff within real observed range\n",
    "    dropoff_range = fake.random_int(0, 10) / 10    \n",
    "\n",
    "    from datetime import timedelta\n",
    "\n",
    "    today = datetime.today()\n",
    "    week_ago = today - timedelta(days=7)\n",
    "    flight_date = fake.date_between_dates(week_ago, today)\n",
    "\n",
    "\n",
    "    # Convert date to string in the desired format\n",
    "    flight_date_str = flight_date.strftime('%m/%d/%Y')  # Convert to string in the format \"%m/%d/%Y\"\n",
    "\n",
    "    customer = {\n",
    "        'FlightDate': flight_date_str,  # Use the formatted string here\n",
    "        'FlightTime': fake.time(),\n",
    "        'Airport': airport,\n",
    "        'MinWaitTime': min_wait,\n",
    "        'MaxWaitTime': max_wait,\n",
    "        'BagNumber': bag_no,\n",
    "        'MaxSpendingRange': max_spending_range,\n",
    "        'DropOffRange': dropoff_range\n",
    "    }\n",
    "\n",
    "    return customer\n",
    "\n",
    "# Generate synthetic customer data\n",
    "synthetic_customers = [generate_data() for i in range(10000)]\n",
    "\n",
    "# Write synthetic data to CSV\n",
    "with open('Synthetic_Data/synthetic_customer_data.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['FlightDate', 'FlightTime', 'Airport', 'MinWaitTime', 'MaxWaitTime', 'BagNumber', 'MaxSpendingRange', 'DropOffRange']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for customer in synthetic_customers:\n",
    "        writer.writerow(customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing num_bags, price_range, dropoff_distance to between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df2 = pd.read_csv('Synthetic_Data/attempt1.csv')\n",
    "features = ['BagNumber', 'MaxSpendingRange','DropOffRange', 'latitude', 'longitude', 'MinWaitTime', 'MaxWaitTime', 'ElapsedTime', 'datetime_sin', 'datetime_cos']\n",
    "\n",
    "def normalize_dataframe(df2, features):\n",
    "    df_normalized = df2.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized[features] = scaler.fit_transform(df_normalized[features])\n",
    "   \n",
    "    return df_normalized\n",
    "\n",
    "df2_normalized = normalize_dataframe(df2, features)\n",
    "df2_normalized.to_csv(\"Synthetic_Data/normalized_synthetic_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# standard scalar\n",
    "df3 = pd.read_csv('Synthetic_Data/normalized_synthetic_data.csv')\n",
    "def standard_scalar(df3, features):\n",
    "    df = df3.copy()\n",
    "    scaler2 = StandardScaler()\n",
    "    df[features] = scaler2.fit_transform(df[features])\n",
    "    return df\n",
    "\n",
    "df3_standard_scalar = standard_scalar(df3, features)\n",
    "df3_standard_scalar.to_csv(\"Synthetic_Data/standard_scalar_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FlightDate FlightTime Airport  MinWaitTime  MaxWaitTime  BagNumber  \\\n",
      "0    2025-01-18   15:29:44     LAX     0.000000     0.916667        0.2   \n",
      "1    2024-03-16   22:23:43     LAX     0.142857     0.750000        0.8   \n",
      "2    2025-01-18   10:57:58     LAX     0.428571     0.666667        0.4   \n",
      "3    2024-03-15   18:30:12     ONT     0.428571     0.583333        0.8   \n",
      "4    2024-12-11   14:44:07     LAX     0.857143     0.416667        0.4   \n",
      "...         ...        ...     ...          ...          ...        ...   \n",
      "9995 2024-03-20   20:35:31     ONT     0.285714     0.500000        0.6   \n",
      "9996 2025-01-18   16:55:38     LAX     0.428571     1.000000        0.2   \n",
      "9997 2024-11-30   20:04:41     LAX     1.000000     0.500000        0.2   \n",
      "9998 2024-12-11   17:19:43     LAX     0.285714     0.250000        0.6   \n",
      "9999 2025-01-18   12:25:13     ONT     0.714286     0.916667        0.2   \n",
      "\n",
      "      MaxSpendingRange  DropOffRange  latitude  longitude  \\\n",
      "0             0.055556           1.0       0.0        0.0   \n",
      "1             0.000000           0.4       0.0        0.0   \n",
      "2             0.222222           0.2       0.0        0.0   \n",
      "3             0.333333           0.8       1.0        1.0   \n",
      "4             0.055556           0.6       0.0        0.0   \n",
      "...                ...           ...       ...        ...   \n",
      "9995          0.166667           0.8       1.0        1.0   \n",
      "9996          0.111111           0.9       0.0        0.0   \n",
      "9997          0.888889           0.2       0.0        0.0   \n",
      "9998          0.111111           0.3       0.0        0.0   \n",
      "9999          0.888889           0.0       1.0        1.0   \n",
      "\n",
      "           FlightDateTime  ElapsedTime  datetime_sin  datetime_cos  \n",
      "0     2025-01-18 15:29:00     0.995660      0.799788      0.999230  \n",
      "1     2024-03-16 22:23:00     0.009386      0.883009      0.996398  \n",
      "2     2025-01-18 10:57:00     0.995054      0.796117      0.999000  \n",
      "3     2024-03-15 18:30:00     0.005662      0.860448      0.998689  \n",
      "4     2024-12-11 14:44:00     0.873763      0.138229      0.381725  \n",
      "...                   ...          ...           ...           ...  \n",
      "9995  2024-03-20 20:35:00     0.021967      0.958923      0.980297  \n",
      "9996  2025-01-18 16:55:00     0.995851      0.800948      0.999296  \n",
      "9997  2024-11-30 20:04:00     0.839218      0.008519      0.029677  \n",
      "9998  2024-12-11 17:19:00     0.874108      0.139699      0.384922  \n",
      "9999  2025-01-18 12:25:00     0.995250      0.797305      0.999077  \n",
      "\n",
      "[10000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cyclical Encoding for Date & Time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"Synthetic_Data/normalized_synthetic_data.csv\")\n",
    "\n",
    "# ensure date and time are in a consistent format \n",
    "# Date: MM/DD/YYYY\n",
    "# Time: HH:MM:SS\n",
    "\n",
    "df['FlightDate'] = pd.to_datetime(df['FlightDate'], format='%Y-%m-%d', errors='coerce')\n",
    "df['FlightTime'] = pd.to_datetime(df['FlightTime'], errors='coerce', format='%H:%M:%S').dt.time\n",
    "\n",
    "\n",
    "# Drop rows where either FlightDate or FlightTime couldn't be parsed\n",
    "df.dropna(subset=['FlightDate', 'FlightTime'], inplace=True)\n",
    "\n",
    "# combine date and time into one column that we can reference as a single variable (1/1/2025 13:00 )\n",
    "df['FlightDateTime'] = df['FlightDate'].astype(str) + \" \" + df['FlightTime'].astype(str)\n",
    "\n",
    "df[\"FlightDateTime\"] = pd.to_datetime(df[\"FlightDateTime\"]).dt.floor('min').dt.strftime(\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "df['FlightDateTime'] = pd.to_datetime(df['FlightDateTime'], format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "# Drop any rows where conversion failed\n",
    "df.dropna(subset=['FlightDateTime'], inplace=True)\n",
    "\n",
    "\n",
    "# Consider the earliest time in our data to serve as our base point (So Maybe January 1, 2024 will be 0)\n",
    "earliest_time = df['FlightDateTime'].min()\n",
    "\n",
    "# Also consider the latest time in ouur data \n",
    "latest_time = df['FlightDateTime'].max()\n",
    "\n",
    "# Calculate the number of minutes between a rows date/time to our base point \n",
    "df[\"ElapsedTime\"] = (((df['FlightDateTime'] - earliest_time).dt.total_seconds()) / 60).astype(int)\n",
    "\n",
    "# Apply the cyclical encoding by mapping with sine and cosine for ciruclar representation where varying times across days will be seen \n",
    " # makes a 2D mapping of time where we can see the relationship between hours of a day and days in a year\n",
    "\n",
    "# total_minutes = (((latest_time - earliest_time).total_seconds()) / 60).astype(int)\n",
    "total_minutes = int(((latest_time - earliest_time).total_seconds()) / 60)\n",
    "\n",
    "\n",
    "df['datetime_sin'] = np.sin(2 * np.pi * df['ElapsedTime'] / total_minutes)\n",
    "\n",
    "df['datetime_cos'] = np.cos(2 * np.pi * df['ElapsedTime'] / total_minutes)\n",
    " \n",
    "df.to_csv(\"Synthetic_Data/attempt1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
