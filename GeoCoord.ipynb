{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googlemaps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgooglemaps\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      4\u001b[0m gmaps \u001b[38;5;241m=\u001b[39m googlemaps\u001b[38;5;241m.\u001b[39mClient(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdd Your Key here\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'googlemaps'"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key='Add Your Key here')\n",
    "\n",
    "# Geocoding an address\n",
    "geocode_result = gmaps.geocode(f'{airport_name} Airport')\n",
    "\n",
    "# Look up an address with reverse geocoding\n",
    "reverse_geocode_result = gmaps.reverse_geocode((40.714224, -73.961452))\n",
    "\n",
    "# Request directions via public transit\n",
    "now = datetime.now()\n",
    "directions_result = gmaps.directions(\"Sydney Town Hall\",\n",
    "                                     \"Parramatta, NSW\",\n",
    "                                     mode=\"transit\",\n",
    "                                     departure_time=now)\n",
    "\n",
    "# Validate an address with address validation\n",
    "addressvalidation_result =  gmaps.addressvalidation(['1600 Amphitheatre Pk'], \n",
    "                                                    regionCode='US',\n",
    "                                                    locality='Mountain View', \n",
    "                                                    enableUspsCass=True)\n",
    "\n",
    "# Get an Address Descriptor of a location in the reverse geocoding response\n",
    "address_descriptor_result = gmaps.reverse_geocode((40.714224, -73.961452), enable_address_descriptor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import googlemaps\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize google maps client\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "gmaps_key = os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "gmaps = googlemaps.Client(key=gmaps_key)\n",
    "\n",
    "# Load in the dataset\n",
    "rides = pd.read_csv(\"RideShares.csv\")\n",
    "\n",
    "# We want to change Airport into a new column consisting of the coordinates of said airport\n",
    "## We can use Google Map's API called Geocoding API / GeoLocation API: https://github.com/googlemaps/google-maps-services-python\n",
    "\n",
    "def get_airport_coordinates(airport_name):\n",
    "    \"\"\"\n",
    "    This function will use OpenStreetMapAPI in order to query for the coordinates of an aiport \n",
    "    \n",
    "    input: airport name we will pass into the API\n",
    "    output: a tuple that holds both (lat, long)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        geocode_result = gmaps.geocode(f'{airport_name} Airport')\n",
    "        if geocode_result: \n",
    "            location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "            return location [\"lat\"], location[\"lng\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching coordinates for {airport_name}: {e}\")\n",
    "    return None, None\n",
    "    \n",
    "# append coordinates to new columns\n",
    "rides[['latitude', 'longitude']] = rides['Airport'].apply(lambda x: pd.Series(get_airport_coordinates(x)))\n",
    "\n",
    "# drop any rows with missing coordinates (if any)\n",
    "rides.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "    \n",
    "# Make this coordinates into a normalized range (Still be able to use Euclidian Distances)\n",
    "scaler = MinMaxScaler()\n",
    "rides[[\"latitude\", \"longitude\"]] = scaler.fit_transform(rides[[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\n",
      "  Using cached faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Faker) (2024.2)\n",
      "Using cached faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
      "Installing collected packages: Faker\n",
      "Successfully installed Faker-37.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# Load existing data\n",
    "df = pd.read_csv('RideShares.csv')\n",
    "df['FlightDate'] = pd.to_datetime(df['FlightDate'], errors='coerce', format='%m/%d/%Y')\n",
    "\n",
    "fake = Faker()\n",
    "random.seed(42)\n",
    "fake.seed_instance(42)\n",
    "\n",
    "def generate_data():\n",
    "    \"\"\"\n",
    "    Generate synthetic data based on real dataset's distributions\n",
    "    \"\"\"\n",
    "\n",
    "#min time for range and max time for range (these will be given in time not time intervals)\n",
    "#prices might vary for ontario vs lax\n",
    "\n",
    "    # Use real airport choices\n",
    "    airport = random.choice(['LAX', 'ONT'])\n",
    "\n",
    "    #min_wait (in .25hr increments)\n",
    "    min_wait = random.choice([x / 60 for x in range(15, 121, 15)])\n",
    "\n",
    "    #max_wait\n",
    "    max_wait = random.choice([x / 60 for x in range(15, 301, 15)])\n",
    "\n",
    "    #max spending range\n",
    "    if random.random() < 0.75:  \n",
    "        max_spending_range = random.randrange(10, 41, 5)\n",
    "    else:  \n",
    "        max_spending_range = random.randrange(40, 101, 5)\n",
    "\n",
    "    # Bags within real observed range\n",
    "    def truncated_normal(mean, std, lower=0, upper=float('inf')):\n",
    "        a, b = (lower - mean) / std, (upper - mean) / std  \n",
    "        return truncnorm.rvs(a, b, loc=mean, scale=std)\n",
    "\n",
    "    mean_bag_number = df['BagNumber'].mean()\n",
    "    std_bag_number = df['BagNumber'].std()\n",
    "    bag_no = round(truncated_normal(mean_bag_number, std_bag_number))\n",
    "    \n",
    "\n",
    "    # Dropoff within real observed range\n",
    "    dropoff_range = fake.random_int(0, 10) / 10    \n",
    "\n",
    "    # Define date ranges for breaks\n",
    "    end_of_winter_break_start = datetime(2025, 1, 18)\n",
    "    end_of_winter_break_end = datetime(2025, 1, 20)\n",
    "    start_of_winter_break_start = datetime(2024, 12, 11)\n",
    "    start_of_winter_break_end = datetime(2024, 12, 14)\n",
    "    spring_break_start = datetime(2024, 3, 14)\n",
    "    spring_break_end = datetime(2024, 3, 23)\n",
    "    thanksgiving_start = datetime(2024, 11, 30)\n",
    "    thanksgiving_end = datetime(2024, 12, 1)\n",
    "\n",
    "    # Randomly choose one of these two periods\n",
    "    period_choice = random.choice([('spring_break', spring_break_start, spring_break_end),\n",
    "                                   ('end_of_winter_break', end_of_winter_break_start, end_of_winter_break_end),\n",
    "                                   ('start_of_winter_break',start_of_winter_break_start,start_of_winter_break_end),\n",
    "                                ('thanksgiving', thanksgiving_start, thanksgiving_end)])\n",
    "\n",
    "    # Sample a date based on the chosen period\n",
    "    period, start_date, end_date = period_choice\n",
    "    flight_date = fake.date_between_dates(start_date, end_date)\n",
    "\n",
    "    # Convert date to string in the desired format\n",
    "    flight_date_str = flight_date.strftime('%m/%d/%Y')  # Convert to string in the format \"%m/%d/%Y\"\n",
    "\n",
    "    customer = {\n",
    "        'FlightDate': flight_date_str,  # Use the formatted string here\n",
    "        'FlightTime': fake.time(),\n",
    "        'Airport': airport,\n",
    "        'MinWaitTime': min_wait,\n",
    "        'MaxWaitTime': max_wait,\n",
    "        'BagNumber': bag_no,\n",
    "        'MaxSpendingRange': max_spending_range,\n",
    "        'DropOffRange': dropoff_range\n",
    "    }\n",
    "\n",
    "    return customer\n",
    "\n",
    "# Generate synthetic customer data\n",
    "synthetic_customers = [generate_data() for i in range(10000)]\n",
    "\n",
    "# Write synthetic data to CSV\n",
    "with open('synthetic_customer_data.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['FlightDate', 'FlightTime', 'Airport', 'MinWaitTime', 'MaxWaitTime', 'BagNumber', 'MaxSpendingRange', 'DropOffRange']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for customer in synthetic_customers:\n",
    "        writer.writerow(customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing num_bags, price_range, dropoff_distance to between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df2 = pd.read_csv('synthetic_customer_data.csv')\n",
    "columns_to_normalize = ['BagNumber', 'MaxSpendingRange','DropOffRange']\n",
    "\n",
    "def normalize_dataframe(df2, columns_to_normalize):\n",
    "    df_normalized = df2.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized[columns_to_normalize] = scaler.fit_transform(df_normalized[columns_to_normalize])\n",
    "    return df_normalized\n",
    "\n",
    "df2_normalized = normalize_dataframe(df2, columns_to_normalize)\n",
    "df2_normalized.to_csv(\"normalized_synthetic_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
